{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive_review.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jafinn14/Pandas-Challenge/blob/master/naive_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rUVgL1wNNajZ",
        "colab": {}
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-U5SGa9gwoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"NaiveBayes\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qnI0zdY5NYCJ",
        "outputId": "ca3dc9ba-1160-4714-8211-f3317663f271",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/yelp_reviews.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"yelp_reviews.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+\n",
            "|   class|                text|\n",
            "+--------+--------------------+\n",
            "|positive|Wow... Loved this...|\n",
            "|negative|  Crust is not good.|\n",
            "|negative|Not tasty and the...|\n",
            "|positive|Stopped by during...|\n",
            "|positive|The selection on ...|\n",
            "|negative|Now I am getting ...|\n",
            "|negative|Honeslty it didn'...|\n",
            "|negative|The potatoes were...|\n",
            "|positive|The fries were gr...|\n",
            "|positive|      A great touch.|\n",
            "|positive|Service was very ...|\n",
            "|negative|  Would not go back.|\n",
            "|negative|The cashier had n...|\n",
            "|positive|I tried the Cape ...|\n",
            "|negative|I was disgusted b...|\n",
            "|negative|I was shocked bec...|\n",
            "|positive| Highly recommended.|\n",
            "|negative|Waitress was a li...|\n",
            "|negative|This place is not...|\n",
            "|negative|did not like at all.|\n",
            "+--------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCDNfpk6rpd8",
        "colab_type": "code",
        "outputId": "30b5e806-0a64-4588-f542-03d5936061ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
            "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.evaluation.BinaryClassificationMetrics object at 0x7fda25298128>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 142, in __del__\n",
            "    self._sc._gateway.detach(self._java_model)\n",
            "AttributeError: 'BinaryClassificationMetrics' object has no attribute '_sc'\n",
            "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.evaluation.BinaryClassificationMetrics object at 0x7fda0f6b04e0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 142, in __del__\n",
            "    self._sc._gateway.detach(self._java_model)\n",
            "AttributeError: 'BinaryClassificationMetrics' object has no attribute '_sc'\n",
            "Exception ignored in: <bound method JavaModelWrapper.__del__ of <pyspark.mllib.evaluation.BinaryClassificationMetrics object at 0x7fda0f6b0630>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/mllib/common.py\", line 142, in __del__\n",
            "    self._sc._gateway.detach(self._java_model)\n",
            "AttributeError: 'BinaryClassificationMetrics' object has no attribute '_sc'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Xyv0tgrpcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# twenty_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CApZu4dirpbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StyjCiGhrpZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sARpZmTWrpSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4BbzYExyNYCR",
        "outputId": "8f68228e-448c-4051-ed8c-24c79dba13d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['text']))\n",
        "data_df.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+\n",
            "|   class|                text|length|\n",
            "+--------+--------------------+------+\n",
            "|positive|Wow... Loved this...|    24|\n",
            "|negative|  Crust is not good.|    18|\n",
            "|negative|Not tasty and the...|    41|\n",
            "|positive|Stopped by during...|    87|\n",
            "|positive|The selection on ...|    59|\n",
            "|negative|Now I am getting ...|    46|\n",
            "|negative|Honeslty it didn'...|    37|\n",
            "|negative|The potatoes were...|   111|\n",
            "|positive|The fries were gr...|    25|\n",
            "|positive|      A great touch.|    14|\n",
            "|positive|Service was very ...|    24|\n",
            "|negative|  Would not go back.|    18|\n",
            "|negative|The cashier had n...|    99|\n",
            "|positive|I tried the Cape ...|    59|\n",
            "|negative|I was disgusted b...|    62|\n",
            "|negative|I was shocked bec...|    50|\n",
            "|positive| Highly recommended.|    19|\n",
            "|negative|Waitress was a li...|    38|\n",
            "|negative|This place is not...|    51|\n",
            "|negative|did not like at all.|    20|\n",
            "+--------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "od7Qj0sxNYCW"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "59dwxefsNYCX",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yssO0_Q5NYCb",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_YyUpR3NYCf",
        "colab": {}
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qBViHQOaNYCj",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDODyxF7NYCn",
        "outputId": "053e0604-cc72-4628-c820-348b7c878b84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(262145,[33933,69...|\n",
            "|  1.0|(262145,[150903,1...|\n",
            "|  1.0|(262145,[63367,11...|\n",
            "|  0.0|(262145,[6286,272...|\n",
            "|  0.0|(262145,[6979,911...|\n",
            "|  1.0|(262145,[24661,34...|\n",
            "|  1.0|(262145,[101702,2...|\n",
            "|  1.0|(262145,[3645,855...|\n",
            "|  0.0|(262145,[53777,13...|\n",
            "|  0.0|(262145,[138356,2...|\n",
            "|  0.0|(262145,[24113,20...|\n",
            "|  1.0|(262145,[172477,1...|\n",
            "|  1.0|(262145,[36200,40...|\n",
            "|  0.0|(262145,[18098,83...|\n",
            "|  1.0|(262145,[89493,95...|\n",
            "|  1.0|(262145,[86431,10...|\n",
            "|  0.0|(262145,[31704,21...|\n",
            "|  1.0|(262145,[27707,65...|\n",
            "|  1.0|(262145,[12329,61...|\n",
            "|  1.0|(262145,[8287,208...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WzfCQmrVNYCr",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zeckHhg5NYCv",
        "outputId": "4e506916-1d44-42a4-8cba-863aa80e9b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   class|                text|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|negative|!....THE OWNERS R...|   120|  1.0|[!....the, owners...|[!....the, owners...|(262144,[14,12946...|(262144,[14,12946...|(262145,[14,12946...|[-1282.7673822704...|[0.99661912345368...|       0.0|\n",
            "|negative|              #NAME?|     6|  1.0|            [#name?]|            [#name?]|(262144,[75443],[...|(262144,[75443],[...|(262145,[75443,26...|[-70.495133606766...|[0.95144457540563...|       0.0|\n",
            "|negative|-Drinks took clos...|    58|  1.0|[-drinks, took, c...|[-drinks, took, c...|(262144,[98627,12...|(262144,[98627,12...|(262145,[98627,12...|[-621.99782261890...|[2.60087216796369...|       1.0|\n",
            "|negative|A FLY was in my a...|    43|  1.0|[a, fly, was, in,...|[fly, apple, juic...|(262144,[146876,2...|(262144,[146876,2...|(262145,[146876,2...|[-428.97772416571...|[0.11966495226939...|       1.0|\n",
            "|negative|After waiting an ...|    75|  1.0|[after, waiting, ...|[waiting, hour, s...|(262144,[17519,98...|(262144,[17519,98...|(262145,[17519,98...|[-569.99960888382...|[2.02894011133674...|       1.0|\n",
            "+--------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEZl4HcWob-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
        "model = nb.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eExahUIuoqgI",
        "colab_type": "code",
        "outputId": "f5c3859e-f4e8-4d46-8e8c-0ad6f162a4d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testing)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % accuracy)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+--------------------+\n",
            "|prediction|label|            features|\n",
            "+----------+-----+--------------------+\n",
            "|       0.0|  1.0|(262145,[14,12946...|\n",
            "|       0.0|  1.0|(262145,[75443,26...|\n",
            "|       1.0|  1.0|(262145,[98627,12...|\n",
            "|       1.0|  1.0|(262145,[146876,2...|\n",
            "|       1.0|  1.0|(262145,[17519,98...|\n",
            "+----------+-----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Accuracy of model at predicting reviews was: 0.736667\n",
            "Test Error = 0.263333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OVFrWcHINYCz",
        "outputId": "7aee7094-3be4-4036-bbb8-294b250e45d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.736324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyrXU-9lh6LY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Create a LogisticRegression instance. This instance is an Estimator.\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
        "# Print out the parameters, documentation, and any default values.\n",
        "# print(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")\n",
        "\n",
        "# Learn a LogisticRegression model. This uses the parameters stored in lr.\n",
        "model1 = lr.fit(training.select('features','label'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvr-x1cDmTlL",
        "colab_type": "code",
        "outputId": "f84ed72d-5ea7-4184-eb3f-902bc998b642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "print(\"Model 1 was fit using parameters: \")\n",
        "print(model1.extractParamMap())\n",
        "\n",
        "# We may alternatively specify parameters using a Python dictionary as a paramMap\n",
        "paramMap = {lr.maxIter: 20}\n",
        "paramMap[lr.maxIter] = 30  # Specify 1 Param, overwriting the original maxIter.\n",
        "paramMap.update({lr.regParam: 0.1, lr.threshold: 0.55})  # Specify multiple Params.\n",
        "\n",
        "# You can combine paramMaps, which are python dictionaries.\n",
        "paramMap2 = {lr.probabilityCol: \"myProbability\"}  # Change output column name\n",
        "paramMapCombined = paramMap.copy()\n",
        "paramMapCombined.update(paramMap2)\n",
        "\n",
        "# Now learn a new model using the paramMapCombined parameters.\n",
        "# paramMapCombined overrides all parameters set earlier via lr.set* methods.\n",
        "model2 = lr.fit(training, paramMapCombined)\n",
        "print(\"Model 2 was fit using parameters: \")\n",
        "print(model2.extractParamMap())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 was fit using parameters: \n",
            "{Param(parent='LogisticRegression_ddc77a3482d5', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent='LogisticRegression_ddc77a3482d5', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent='LogisticRegression_ddc77a3482d5', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto', Param(parent='LogisticRegression_ddc77a3482d5', name='featuresCol', doc='features column name'): 'features', Param(parent='LogisticRegression_ddc77a3482d5', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent='LogisticRegression_ddc77a3482d5', name='labelCol', doc='label column name'): 'label', Param(parent='LogisticRegression_ddc77a3482d5', name='maxIter', doc='maximum number of iterations (>= 0)'): 10, Param(parent='LogisticRegression_ddc77a3482d5', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='LogisticRegression_ddc77a3482d5', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'probability', Param(parent='LogisticRegression_ddc77a3482d5', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='LogisticRegression_ddc77a3482d5', name='regParam', doc='regularization parameter (>= 0)'): 0.01, Param(parent='LogisticRegression_ddc77a3482d5', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent='LogisticRegression_ddc77a3482d5', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.5, Param(parent='LogisticRegression_ddc77a3482d5', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}\n",
            "Model 2 was fit using parameters: \n",
            "{Param(parent='LogisticRegression_ddc77a3482d5', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent='LogisticRegression_ddc77a3482d5', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent='LogisticRegression_ddc77a3482d5', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.'): 'auto', Param(parent='LogisticRegression_ddc77a3482d5', name='featuresCol', doc='features column name'): 'features', Param(parent='LogisticRegression_ddc77a3482d5', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent='LogisticRegression_ddc77a3482d5', name='labelCol', doc='label column name'): 'label', Param(parent='LogisticRegression_ddc77a3482d5', name='maxIter', doc='maximum number of iterations (>= 0)'): 30, Param(parent='LogisticRegression_ddc77a3482d5', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='LogisticRegression_ddc77a3482d5', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities'): 'myProbability', Param(parent='LogisticRegression_ddc77a3482d5', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name'): 'rawPrediction', Param(parent='LogisticRegression_ddc77a3482d5', name='regParam', doc='regularization parameter (>= 0)'): 0.1, Param(parent='LogisticRegression_ddc77a3482d5', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent='LogisticRegression_ddc77a3482d5', name='threshold', doc='threshold in binary classification prediction, in range [0, 1]'): 0.55, Param(parent='LogisticRegression_ddc77a3482d5', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFmwI1EZmKMK",
        "colab_type": "code",
        "outputId": "6229d0cd-3f10-4885-b83c-91b5c6cb509d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "prediction = model1.transform(testing.select('features','label'))\n",
        "prediction\n",
        "# result = prediction.select(\"features\", \"label\", \"probability\", \"prediction\") \\\n",
        "#     .collect()\n",
        "\n",
        "# for row in result:\n",
        "#     print(\"features=%s, label=%s -> prob=%s, prediction=%s\"\n",
        "#           % (row.features, row.label, row.myProbability, row.prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlqrPt0snJM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# metrics = BinaryClassificationMetrics(prediction.select('features','label').collect())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bOpKc638NlCQ",
        "colab": {}
      },
      "source": [
        "# from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "# metrics = BinaryClassificationMetrics(test_results.select('prediction','label'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUl1zSyZhZry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictionAndLabels = testing.map(lambda lp: (float(model.predict(lp.features)), lp.label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oepQLCNhf5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
        "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
        "from pyspark.mllib.util import MLUtils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yZCWX75iKzj",
        "colab_type": "code",
        "outputId": "09d6de21-21a9-4f6a-a36e-c401378ecc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# Run training algorithm to build the model\\\n",
        "train = training.rdd.map(list)\n",
        "test = testing.rdd.map(list)\n",
        "\n",
        "model = LogisticRegressionWithLBFGS.train(train)\n",
        "\n",
        "# Compute raw scores on the test set\n",
        "predictionAndLabels = test.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
        "\n",
        "# Instantiate metrics object\n",
        "metrics = BinaryClassificationMetrics(predictionAndLabels)\n",
        "\n",
        "# Area under precision-recall curve\n",
        "print(\"Area under PR = %s\" % metrics.areaUnderPR)\n",
        "\n",
        "# Area under ROC curve\n",
        "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-346f8b6ab131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute raw scores on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-2.4.5-bin-hadoop2.7/python/pyspark/mllib/classification.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, data, iterations, initialWeights, regParam, regType, intercept, corrections, tolerance, validateData, numClasses)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitialWeights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumClasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0minitialWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'features'"
          ]
        }
      ]
    }
  ]
}